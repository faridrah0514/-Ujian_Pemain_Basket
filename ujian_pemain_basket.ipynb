{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitc6d373802fa94bc18802ec892f301229",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soal 1 - Hunting Pemain Basket üèÄ\n",
    "\n",
    "Anda adalah seorang manager klub basket ternama yang ingin merekrut pemain basket muda berbakat. Pemain yang Anda targetkan untuk direkrut memiliki kriteria sebagai berikut:\n",
    "\n",
    "- Usia (Age) <= 25 tahun,\n",
    "- Tinggi badan (Height) >= 180 cm,\n",
    "- Berat badan (Weight) <= 90 kg,\n",
    "- Rata-rata point (Average points scored) >= 6, dan\n",
    "- Rata-rata rebound (Average rebounds grabbed) >= 3.\n",
    "\n",
    "Tersedia 1 buah dataset (.csv) yang memuat data lengkap pemain basket liga profesional NBA (National Basketball Association). Unduh dataset via Kaggle: klik di sini. Dengan memanfaatkan dataset tersebut, buatlah sebuah file Jupyter notebook (.ipynb) yang berisi model machine learning untuk mengklasifikasikan data pemain muda Indonesia di bawah ini apakah tergolong pemain yang patut Anda rekrut atau tidak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>player_name</th>\n      <th>team_abbreviation</th>\n      <th>age</th>\n      <th>player_height</th>\n      <th>player_weight</th>\n      <th>college</th>\n      <th>country</th>\n      <th>draft_year</th>\n      <th>draft_round</th>\n      <th>...</th>\n      <th>pts</th>\n      <th>reb</th>\n      <th>ast</th>\n      <th>net_rating</th>\n      <th>oreb_pct</th>\n      <th>dreb_pct</th>\n      <th>usg_pct</th>\n      <th>ts_pct</th>\n      <th>ast_pct</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Chris Robinson</td>\n      <td>VAN</td>\n      <td>23.0</td>\n      <td>195.58</td>\n      <td>90.71840</td>\n      <td>Western Kentucky</td>\n      <td>USA</td>\n      <td>1996</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4.6</td>\n      <td>1.7</td>\n      <td>1.6</td>\n      <td>-11.4</td>\n      <td>0.039</td>\n      <td>0.088</td>\n      <td>0.155</td>\n      <td>0.486</td>\n      <td>0.156</td>\n      <td>1996-97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Matt Fish</td>\n      <td>MIA</td>\n      <td>27.0</td>\n      <td>210.82</td>\n      <td>106.59412</td>\n      <td>North Carolina-Wilmington</td>\n      <td>USA</td>\n      <td>1992</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.3</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>-15.1</td>\n      <td>0.143</td>\n      <td>0.267</td>\n      <td>0.265</td>\n      <td>0.333</td>\n      <td>0.000</td>\n      <td>1996-97</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Matt Bullard</td>\n      <td>HOU</td>\n      <td>30.0</td>\n      <td>208.28</td>\n      <td>106.59412</td>\n      <td>Iowa</td>\n      <td>USA</td>\n      <td>Undrafted</td>\n      <td>Undrafted</td>\n      <td>...</td>\n      <td>4.5</td>\n      <td>1.6</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.016</td>\n      <td>0.115</td>\n      <td>0.151</td>\n      <td>0.535</td>\n      <td>0.099</td>\n      <td>1996-97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Marty Conlon</td>\n      <td>BOS</td>\n      <td>29.0</td>\n      <td>210.82</td>\n      <td>111.13004</td>\n      <td>Providence</td>\n      <td>USA</td>\n      <td>Undrafted</td>\n      <td>Undrafted</td>\n      <td>...</td>\n      <td>7.8</td>\n      <td>4.4</td>\n      <td>1.4</td>\n      <td>-9.0</td>\n      <td>0.083</td>\n      <td>0.152</td>\n      <td>0.167</td>\n      <td>0.542</td>\n      <td>0.101</td>\n      <td>1996-97</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Martin Muursepp</td>\n      <td>DAL</td>\n      <td>22.0</td>\n      <td>205.74</td>\n      <td>106.59412</td>\n      <td>None</td>\n      <td>USA</td>\n      <td>1996</td>\n      <td>1</td>\n      <td>...</td>\n      <td>3.7</td>\n      <td>1.6</td>\n      <td>0.5</td>\n      <td>-14.5</td>\n      <td>0.109</td>\n      <td>0.118</td>\n      <td>0.233</td>\n      <td>0.482</td>\n      <td>0.114</td>\n      <td>1996-97</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 22 columns</p>\n</div>",
      "text/plain": "   Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n0           0   Chris Robinson               VAN  23.0         195.58   \n1           1        Matt Fish               MIA  27.0         210.82   \n2           2     Matt Bullard               HOU  30.0         208.28   \n3           3     Marty Conlon               BOS  29.0         210.82   \n4           4  Martin Muursepp               DAL  22.0         205.74   \n\n   player_weight                    college country draft_year draft_round  \\\n0       90.71840           Western Kentucky     USA       1996           2   \n1      106.59412  North Carolina-Wilmington     USA       1992           2   \n2      106.59412                       Iowa     USA  Undrafted   Undrafted   \n3      111.13004                 Providence     USA  Undrafted   Undrafted   \n4      106.59412                       None     USA       1996           1   \n\n   ...  pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n0  ...  4.6  1.7  1.6       -11.4     0.039     0.088    0.155   0.486   \n1  ...  0.3  0.8  0.0       -15.1     0.143     0.267    0.265   0.333   \n2  ...  4.5  1.6  0.9         0.9     0.016     0.115    0.151   0.535   \n3  ...  7.8  4.4  1.4        -9.0     0.083     0.152    0.167   0.542   \n4  ...  3.7  1.6  0.5       -14.5     0.109     0.118    0.233   0.482   \n\n   ast_pct   season  \n0    0.156  1996-97  \n1    0.000  1996-97  \n2    0.099  1996-97  \n3    0.101  1996-97  \n4    0.114  1996-97  \n\n[5 rows x 22 columns]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba = pd.read_csv('all_seasons.csv')\n",
    "df_nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9561 entries, 0 to 9560\nData columns (total 22 columns):\nUnnamed: 0           9561 non-null int64\nplayer_name          9561 non-null object\nteam_abbreviation    9561 non-null object\nage                  9561 non-null float64\nplayer_height        9561 non-null float64\nplayer_weight        9561 non-null float64\ncollege              9561 non-null object\ncountry              9561 non-null object\ndraft_year           9561 non-null object\ndraft_round          9561 non-null object\ndraft_number         9561 non-null object\ngp                   9561 non-null int64\npts                  9561 non-null float64\nreb                  9561 non-null float64\nast                  9561 non-null float64\nnet_rating           9561 non-null float64\noreb_pct             9561 non-null float64\ndreb_pct             9561 non-null float64\nusg_pct              9561 non-null float64\nts_pct               9561 non-null float64\nast_pct              9561 non-null float64\nseason               9561 non-null object\ndtypes: float64(12), int64(2), object(8)\nmemory usage: 1.6+ MB\n"
    }
   ],
   "source": [
    "df_nba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0           0\nplayer_name          0\nteam_abbreviation    0\nage                  0\nplayer_height        0\nplayer_weight        0\ncollege              0\ncountry              0\ndraft_year           0\ndraft_round          0\ndraft_number         0\ngp                   0\npts                  0\nreb                  0\nast                  0\nnet_rating           0\noreb_pct             0\ndreb_pct             0\nusg_pct              0\nts_pct               0\nast_pct              0\nseason               0\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player_name</th>\n      <th>team_abbreviation</th>\n      <th>age</th>\n      <th>player_height</th>\n      <th>player_weight</th>\n      <th>pts</th>\n      <th>reb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chris Robinson</td>\n      <td>VAN</td>\n      <td>23.0</td>\n      <td>195.58</td>\n      <td>90.71840</td>\n      <td>4.6</td>\n      <td>1.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Matt Fish</td>\n      <td>MIA</td>\n      <td>27.0</td>\n      <td>210.82</td>\n      <td>106.59412</td>\n      <td>0.3</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Matt Bullard</td>\n      <td>HOU</td>\n      <td>30.0</td>\n      <td>208.28</td>\n      <td>106.59412</td>\n      <td>4.5</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Marty Conlon</td>\n      <td>BOS</td>\n      <td>29.0</td>\n      <td>210.82</td>\n      <td>111.13004</td>\n      <td>7.8</td>\n      <td>4.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Martin Muursepp</td>\n      <td>DAL</td>\n      <td>22.0</td>\n      <td>205.74</td>\n      <td>106.59412</td>\n      <td>3.7</td>\n      <td>1.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       player_name team_abbreviation   age  player_height  player_weight  pts  \\\n0   Chris Robinson               VAN  23.0         195.58       90.71840  4.6   \n1        Matt Fish               MIA  27.0         210.82      106.59412  0.3   \n2     Matt Bullard               HOU  30.0         208.28      106.59412  4.5   \n3     Marty Conlon               BOS  29.0         210.82      111.13004  7.8   \n4  Martin Muursepp               DAL  22.0         205.74      106.59412  3.7   \n\n   reb  \n0  1.7  \n1  0.8  \n2  1.6  \n3  4.4  \n4  1.6  "
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba = df_nba[['player_name', 'team_abbreviation', 'age', 'player_height', 'player_weight', 'pts', 'reb']]\n",
    "df_nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba['status'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n"
    }
   ],
   "source": [
    "df_nba['status'][(df_nba['age'] <= 25) & (df_nba['player_height'] >= 180) & (df_nba['player_weight'] <=90) & (df_nba['pts'] >=6) & (df_nba['reb'] >= 3)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player_name</th>\n      <th>team_abbreviation</th>\n      <th>age</th>\n      <th>player_height</th>\n      <th>player_weight</th>\n      <th>pts</th>\n      <th>reb</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>Kerry Kittles</td>\n      <td>NJN</td>\n      <td>23.0</td>\n      <td>195.58</td>\n      <td>81.192968</td>\n      <td>16.4</td>\n      <td>3.9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>Allen Iverson</td>\n      <td>PHI</td>\n      <td>22.0</td>\n      <td>182.88</td>\n      <td>74.842680</td>\n      <td>23.5</td>\n      <td>4.1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>Eddie Jones</td>\n      <td>LAL</td>\n      <td>25.0</td>\n      <td>198.12</td>\n      <td>86.182480</td>\n      <td>17.2</td>\n      <td>4.1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>Kerry Kittles</td>\n      <td>NJN</td>\n      <td>24.0</td>\n      <td>195.58</td>\n      <td>81.192968</td>\n      <td>17.2</td>\n      <td>4.7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>Allen Iverson</td>\n      <td>PHI</td>\n      <td>23.0</td>\n      <td>182.88</td>\n      <td>74.842680</td>\n      <td>22.0</td>\n      <td>3.7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9345</th>\n      <td>Brandon Ingram</td>\n      <td>LAL</td>\n      <td>19.0</td>\n      <td>205.74</td>\n      <td>86.182480</td>\n      <td>9.4</td>\n      <td>4.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9371</th>\n      <td>D'Angelo Russell</td>\n      <td>LAL</td>\n      <td>21.0</td>\n      <td>195.58</td>\n      <td>88.450440</td>\n      <td>15.6</td>\n      <td>3.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9485</th>\n      <td>Jeremy Lamb</td>\n      <td>CHA</td>\n      <td>25.0</td>\n      <td>195.58</td>\n      <td>83.914520</td>\n      <td>9.7</td>\n      <td>4.3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9522</th>\n      <td>Dennis Schroder</td>\n      <td>ATL</td>\n      <td>23.0</td>\n      <td>185.42</td>\n      <td>78.017824</td>\n      <td>17.9</td>\n      <td>3.1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9557</th>\n      <td>Elfrid Payton</td>\n      <td>ORL</td>\n      <td>23.0</td>\n      <td>193.04</td>\n      <td>83.914520</td>\n      <td>12.8</td>\n      <td>4.7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>191 rows √ó 8 columns</p>\n</div>",
      "text/plain": "           player_name team_abbreviation   age  player_height  player_weight  \\\n105      Kerry Kittles               NJN  23.0         195.58      81.192968   \n290      Allen Iverson               PHI  22.0         182.88      74.842680   \n432        Eddie Jones               LAL  25.0         198.12      86.182480   \n659      Kerry Kittles               NJN  24.0         195.58      81.192968   \n835      Allen Iverson               PHI  23.0         182.88      74.842680   \n...                ...               ...   ...            ...            ...   \n9345    Brandon Ingram               LAL  19.0         205.74      86.182480   \n9371  D'Angelo Russell               LAL  21.0         195.58      88.450440   \n9485       Jeremy Lamb               CHA  25.0         195.58      83.914520   \n9522   Dennis Schroder               ATL  23.0         185.42      78.017824   \n9557     Elfrid Payton               ORL  23.0         193.04      83.914520   \n\n       pts  reb  status  \n105   16.4  3.9       1  \n290   23.5  4.1       1  \n432   17.2  4.1       1  \n659   17.2  4.7       1  \n835   22.0  3.7       1  \n...    ...  ...     ...  \n9345   9.4  4.0       1  \n9371  15.6  3.5       1  \n9485   9.7  4.3       1  \n9522  17.9  3.1       1  \n9557  12.8  4.7       1  \n\n[191 rows x 8 columns]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba[(df_nba['age'] <= 25) & (df_nba['player_height'] >= 180) & (df_nba['player_weight'] <=90) & (df_nba['pts'] >=6) & (df_nba['reb'] >= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_excel('test.xlsx')\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lakukan Standardisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(9561, 5)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba[['age', 'player_height', 'player_weight', 'pts', 'reb']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "val  = scaler.fit_transform(df_nba[['age', 'player_height', 'player_weight', 'pts', 'reb']])\n",
    "# val\n",
    "# val=df_nba[['age', 'player_height', 'player_weight', 'pts', 'reb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(9561,)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba['status'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split menjadi 82% untuk training set & 18% untuk testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7840"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(val, df_nba['status'], test_size= .18)\n",
    "len(x_train) #=> test_size 18%"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Buatlah 3 model machine learning untuk klasifikasi (pilihan model bebas), lakukan hyperparameter tuning untuk menentukan nilai parameter terbaik tiap model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "89\n"
    }
   ],
   "source": [
    "LR_param={\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'dual': [True, False],\n",
    "    # 'class_weight': ['dict', 'balanced'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [1,10,100,1000],\n",
    "    'multi_class':['auto', 'ovr','multinomial'],\n",
    "    'warm_start': [True, False]\n",
    "}\n",
    "DTree_param={\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "print(int(round((np.sqrt(len(x_train)))))) #=> 89\n",
    "KN_param={\n",
    "    'n_neighbors':[3, 11, 21, 57, 89],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: penalty='none' is not supported for the liblinear solver\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: penalty='none' is not supported for the liblinear solver\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: penalty='none' is not supported for the liblinear solver\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver liblinear does not support a multinomial backend.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nValueError: penalty='none' is not supported for the liblinear solver\n\n  FitFailedWarning)\nC:\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n"
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                            metric='minkowski',\n                                            metric_params=None, n_jobs=None,\n                                            n_neighbors=5, p=2,\n                                            weights='uniform'),\n             iid='deprecated', n_jobs=None,\n             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                         'n_neighbors': [3, 11, 21, 57, 89]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR_ori = LogisticRegression()\n",
    "model_LR = GridSearchCV(\n",
    "    estimator=model_LR_ori,\n",
    "    param_grid=LR_param,\n",
    "    cv=5\n",
    ")\n",
    "model_DT_ori = DecisionTreeClassifier()\n",
    "model_DT = GridSearchCV(\n",
    "    estimator=model_DT_ori,\n",
    "    param_grid=DTree_param,\n",
    "    cv=5\n",
    ")\n",
    "model_KN_ori = KNeighborsClassifier()\n",
    "model_KN = GridSearchCV(\n",
    "    estimator=model_KN_ori,\n",
    "    param_grid=KN_param,\n",
    "    cv=5\n",
    ")\n",
    "model_LR.fit(x_train, y_train)\n",
    "model_DT.fit(x_train, y_train)\n",
    "model_KN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'dual': False, 'max_iter': 10, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'sag', 'warm_start': True}\n"
    }
   ],
   "source": [
    "print(model_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'criterion': 'gini', 'max_features': 'log2', 'splitter': 'best'}\n"
    }
   ],
   "source": [
    "print(model_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'algorithm': 'auto', 'n_neighbors': 11}\n"
    }
   ],
   "source": [
    "print(model_KN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n"
    },
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR_param_optim={'dual': False, 'max_iter': 10, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'saga', 'warm_start': True}\n",
    "LR_param_optim=model_LR.best_params_\n",
    "# DTree_param_optim={'criterion': 'entropy', 'max_features': 'log2', 'splitter': 'best'}\n",
    "DTree_param_optim=model_DT.best_params_\n",
    "# KN_param_optim={'algorithm': 'auto', 'n_neighbors': 11}\n",
    "KN_param_optim=model_KN.best_params_\n",
    "model_LR_optim = LogisticRegression(**LR_param_optim)\n",
    "model_DT_optim = DecisionTreeClassifier(**DTree_param_optim)\n",
    "model_KN_optim = KNeighborsClassifier(**KN_param_optim)\n",
    "\n",
    "model_LR_optim.fit(x_train, y_train)\n",
    "model_DT_optim.fit(x_train, y_train)\n",
    "model_KN_optim.fit(x_train, y_train)\n",
    "\n",
    "model_LR_optim.predict(x_test)\n",
    "model_DT_optim.predict(x_test)\n",
    "model_KN_optim.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Logistic Regression: 0.9872167344567112\nDecision Tree: 0.9930273097036607\nKNN: 0.9912841371295759\n"
    }
   ],
   "source": [
    "print(\"Logistic Regression:\",accuracy_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"Decision Tree:\", accuracy_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"KNN:\", accuracy_score(y_test, model_KN_optim.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gunakan parameter terbaik model untuk melakukan prediksi pada testing set. Kemudian hitung evaluation metrics tiap model. Metrics yang wajib dihitung yakni: balanced accuracy, precision, recall, F1 score & ROC AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Logistic Regression: 0.6905377808032676\nDecision Tree: 0.9017812570909916\nKNN: 0.8251531654186521\n"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(\"Logistic Regression:\", balanced_accuracy_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"Decision Tree:\",balanced_accuracy_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"KNN:\",balanced_accuracy_score(y_test, model_KN_optim.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Precision Linear Regression\nPrecision (+): 0.625\nPrecision (-): 0.375\n\nPrecision Decision Tree\nPrecision (+): 0.75\nPrecision (-): 0.25\n\nPrecision KNN\nPrecision (+): 0.7391304347826086\nPrecision (-): 0.26086956521739135\n"
    }
   ],
   "source": [
    "# print('7. precision (+):', tp / (tp + fp))\n",
    "# print('8. precision (-):', 1 - (tp/(tp+fp)))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn1, fp1, fn1, tp1 = confusion_matrix(y_test, model_LR_optim.predict(x_test)).ravel()\n",
    "tn2, fp2, fn2, tp2 = confusion_matrix(y_test, model_DT_optim.predict(x_test)).ravel()\n",
    "tn3, fp3, fn3, tp3 = confusion_matrix(y_test, model_KN_optim.predict(x_test)).ravel()\n",
    "\n",
    "print(\"Precision Linear Regression\")\n",
    "print(\"Precision (+):\", tp1/(tp1 + fp1))\n",
    "print(\"Precision (-):\", 1- tp1/(tp1 + fp1))\n",
    "print(\"\")\n",
    "print(\"Precision Decision Tree\")\n",
    "print(\"Precision (+):\", tp2/(tp2 + fp2))\n",
    "print(\"Precision (-):\", 1- tp2/(tp2 + fp2))\n",
    "print(\"\")\n",
    "print(\"Precision KNN\")\n",
    "print(\"Precision (+):\", tp3/(tp3 + fp3))\n",
    "print(\"Precision (-):\", 1- tp3/(tp3 + fp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Recall Linear Regression\nRecall (+): 0.38461538461538464\nRecall (-): 0.38461538461538464\n\nRecall Decision Tree\nRecall (+): 0.8076923076923077\nRecall (-): 0.8076923076923077\n\nRecall KNN\nRecall (+): 0.6538461538461539\nRecall (-): 0.6538461538461539\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall Linear Regression\")\n",
    "print(\"Recall (+):\", recall_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"Recall (-):\", recall_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"\")\n",
    "print(\"Recall Decision Tree\")\n",
    "print(\"Recall (+):\", recall_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"Recall (-):\", recall_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"\")\n",
    "print(\"Recall KNN\")\n",
    "print(\"Recall (+):\", recall_score(y_test, model_KN_optim.predict(x_test)))\n",
    "print(\"Recall (-):\", recall_score(y_test, model_KN_optim.predict(x_test)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "F1 Score Linear Regression\nF1 Score (+): 0.4761904761904762\nF1 Score (-): 0.4761904761904762\n\nF1 Score Decision Tree\nF1 Score (+): 0.7777777777777779\nF1 Score (-): 0.7777777777777779\n\nF1 Score KNN\nF1 Score (+): 0.693877551020408\nF1 Score (-): 0.693877551020408\n"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score Linear Regression\")\n",
    "print(\"F1 Score (+):\", f1_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"F1 Score (-):\", f1_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"\")\n",
    "print(\"F1 Score Decision Tree\")\n",
    "print(\"F1 Score (+):\", f1_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"F1 Score (-):\", f1_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"\")\n",
    "print(\"F1 Score KNN\")\n",
    "print(\"F1 Score (+):\", f1_score(y_test, model_KN_optim.predict(x_test)))\n",
    "print(\"F1 Score (-):\", f1_score(y_test, model_KN_optim.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ROC_AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Logistic Regression: 0.6905377808032676\nDecision Tree: 0.9017812570909917\nKNN: 0.8251531654186521\n"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Logistic Regression:\", roc_auc_score(y_test, model_LR_optim.predict(x_test)))\n",
    "print(\"Decision Tree:\", roc_auc_score(y_test, model_DT_optim.predict(x_test)))\n",
    "print(\"KNN:\", roc_auc_score(y_test, model_KN_optim.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The Winner is \"Decision Tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Club</th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>Avg Points</th>\n      <th>Avg Rebounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andakara Prastawa Dyaksa</td>\n      <td>Pelita Jaya Bakrie</td>\n      <td>Indonesia</td>\n      <td>24</td>\n      <td>190</td>\n      <td>90</td>\n      <td>7</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Reggie Mononimbar</td>\n      <td>Pelita Jaya Bakrie</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>185</td>\n      <td>86</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hardianus Lakudu</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>23</td>\n      <td>178</td>\n      <td>83</td>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kevin Yonas Sitorus</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>26</td>\n      <td>185</td>\n      <td>75</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arki Dikania Wisnu</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>20</td>\n      <td>183</td>\n      <td>80</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Laurentius Steven Oei</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>191</td>\n      <td>85</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Mei Joni</td>\n      <td>Stapac</td>\n      <td>Indonesia</td>\n      <td>25</td>\n      <td>188</td>\n      <td>90</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Vincent Rivaldi Kosasih</td>\n      <td>Stapac</td>\n      <td>Indonesia</td>\n      <td>23</td>\n      <td>179</td>\n      <td>87</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Hardian Wicaksono</td>\n      <td>Pacific Caesar Surabaya</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>177</td>\n      <td>80</td>\n      <td>9</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Brandon Jawato</td>\n      <td>Louvre Surabaya</td>\n      <td>Indonesia</td>\n      <td>24</td>\n      <td>182</td>\n      <td>85</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                       Name                           Club     Country  Age  \\\n0  Andakara Prastawa Dyaksa             Pelita Jaya Bakrie  ¬†Indonesia   24   \n1         Reggie Mononimbar             Pelita Jaya Bakrie  ¬†Indonesia   21   \n2          Hardianus Lakudu  Satria Muda Pertamina Jakarta  ¬†Indonesia   23   \n3       Kevin Yonas Sitorus  Satria Muda Pertamina Jakarta  ¬†Indonesia   26   \n4        Arki Dikania Wisnu  Satria Muda Pertamina Jakarta  ¬†Indonesia   20   \n5     Laurentius Steven Oei  Satria Muda Pertamina Jakarta  ¬†Indonesia   21   \n6                  Mei Joni                         Stapac  ¬†Indonesia   25   \n7   Vincent Rivaldi Kosasih                         Stapac  ¬†Indonesia   23   \n8         Hardian Wicaksono        Pacific Caesar Surabaya  ¬†Indonesia   21   \n9            Brandon Jawato                Louvre Surabaya  ¬†Indonesia   24   \n\n   Height  Weight  Avg Points  Avg Rebounds  \n0     190      90           7             6  \n1     185      86           6             3  \n2     178      83          10             3  \n3     185      75          11             4  \n4     183      80           5             2  \n5     191      85           4            10  \n6     188      90           7             5  \n7     179      87           1             2  \n8     177      80           9             8  \n9     182      85           6             5  "
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_excel('test.xlsx')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Usia (Age) <= 25 tahun,\n",
    "- Tinggi badan (Height) >= 180 cm,\n",
    "- Berat badan (Weight) <= 90 kg,\n",
    "- Rata-rata point (Average points scored) >= 6, dan\n",
    "- Rata-rata rebound (Average rebounds grabbed) >= 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('standardscaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('decisiontreeclassifier',\n                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                                        criterion='gini', max_depth=None,\n                                        max_features='log2',\n                                        max_leaf_nodes=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        presort='deprecated', random_state=None,\n                                        splitter='best'))],\n         verbose=False)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_nba[['age', 'player_height', 'player_weight', 'pts', 'reb']], df_nba['status'], test_size=0.18)\n",
    "\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier(**model_DT.best_params_)\n",
    "    # model_DT_optim\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "# model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Club</th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>Avg Points</th>\n      <th>Avg Rebounds</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andakara Prastawa Dyaksa</td>\n      <td>Pelita Jaya Bakrie</td>\n      <td>Indonesia</td>\n      <td>24</td>\n      <td>190</td>\n      <td>90</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Reggie Mononimbar</td>\n      <td>Pelita Jaya Bakrie</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>185</td>\n      <td>86</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hardianus Lakudu</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>23</td>\n      <td>178</td>\n      <td>83</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kevin Yonas Sitorus</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>26</td>\n      <td>185</td>\n      <td>75</td>\n      <td>11</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arki Dikania Wisnu</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>20</td>\n      <td>183</td>\n      <td>80</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Laurentius Steven Oei</td>\n      <td>Satria Muda Pertamina Jakarta</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>191</td>\n      <td>85</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Mei Joni</td>\n      <td>Stapac</td>\n      <td>Indonesia</td>\n      <td>25</td>\n      <td>188</td>\n      <td>90</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Vincent Rivaldi Kosasih</td>\n      <td>Stapac</td>\n      <td>Indonesia</td>\n      <td>23</td>\n      <td>179</td>\n      <td>87</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Hardian Wicaksono</td>\n      <td>Pacific Caesar Surabaya</td>\n      <td>Indonesia</td>\n      <td>21</td>\n      <td>177</td>\n      <td>80</td>\n      <td>9</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Brandon Jawato</td>\n      <td>Louvre Surabaya</td>\n      <td>Indonesia</td>\n      <td>24</td>\n      <td>182</td>\n      <td>85</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                       Name                           Club     Country  Age  \\\n0  Andakara Prastawa Dyaksa             Pelita Jaya Bakrie  ¬†Indonesia   24   \n1         Reggie Mononimbar             Pelita Jaya Bakrie  ¬†Indonesia   21   \n2          Hardianus Lakudu  Satria Muda Pertamina Jakarta  ¬†Indonesia   23   \n3       Kevin Yonas Sitorus  Satria Muda Pertamina Jakarta  ¬†Indonesia   26   \n4        Arki Dikania Wisnu  Satria Muda Pertamina Jakarta  ¬†Indonesia   20   \n5     Laurentius Steven Oei  Satria Muda Pertamina Jakarta  ¬†Indonesia   21   \n6                  Mei Joni                         Stapac  ¬†Indonesia   25   \n7   Vincent Rivaldi Kosasih                         Stapac  ¬†Indonesia   23   \n8         Hardian Wicaksono        Pacific Caesar Surabaya  ¬†Indonesia   21   \n9            Brandon Jawato                Louvre Surabaya  ¬†Indonesia   24   \n\n   Height  Weight  Avg Points  Avg Rebounds  status  \n0     190      90           7             6       1  \n1     185      86           6             3       1  \n2     178      83          10             3       0  \n3     185      75          11             4       0  \n4     183      80           5             2       0  \n5     191      85           4            10       0  \n6     188      90           7             5       1  \n7     179      87           1             2       0  \n8     177      80           9             8       0  \n9     182      85           6             5       1  "
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['status'] = model.predict(df_test[['Age', 'Height', 'Weight', 'Avg Points', 'Avg Rebounds']])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}